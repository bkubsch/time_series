{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Time series data cleaning__\n",
    "\n",
    "Usually, data scientists spend most time on data cleaning, analysis, and preparation. \n",
    "\n",
    "In this notebook we will reformat, look at, and prepare our dataset with the goal of using XGBoost for prediction. \n",
    "\n",
    "## __XGBoost__\n",
    "\n",
    "XGBoost is not a classical time series prediction model, but it is commonly used for time series predictions. \n",
    "\n",
    "It is assumed you have knowledge of XGBoost and how it works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Marginal CO2 emissions__\n",
    "\n",
    "The dataset we are using is the CO2 marginal emissions data from the Australian energy market.  This is a challenging time series!\n",
    "\n",
    "The dataset includes the marginal CO2 emissions (t CO2 / MWh) together with a time stamp (DateTime) associated to it. The marginal CO2 emissions are measured every 5 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Data exploration and imputation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __The dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/marginal_emissions_raw.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Exercise 1__\n",
    "\n",
    "- Check the datatype of the \"DateTime\" column of our dataframe \"df\".\n",
    "- Change the index of our dataframe \"df\" to a DateTimeIndex, using our \"DateTime\" column.\n",
    "\n",
    "Make sure you get rid of the original index column (starting with: 0, 1, 2, 3,...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Your solution 1:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_pickle('../data/marginal_emissions_dtindex.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Train / test split__\n",
    "\n",
    "It is mandatory to perform the train / test split of a dataset before any pre-analysis before training, e.g. before the identification of potential predictors. So now that we have the format right, let's do that right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's see what the time range of our dataset is\n",
    "print(df.index.min())\n",
    "print(df.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have plenty of data; let's go and use a bit more than a year as our test and the remaing period as our training set\n",
    "#NOTE: time series forecasts request that any training is done on data that lie in the past relative to the test data\n",
    "\n",
    "train = df[df.index < dt.datetime(2018,6,1,0,0,0)]\n",
    "test = df[df.index >= (dt.datetime(2018,6,1,0,0,0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.index.min())\n",
    "print(train.index.max())\n",
    "\n",
    "print(test.index.min())\n",
    "print(test.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train.index.max() < test.index.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_pickle('../data/train.pkl')\n",
    "test.to_pickle('../data/test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let us redefine df in order to leave the test set alone\n",
    "df = train\n",
    "\n",
    "print(df.index.min())\n",
    "print(df.index.max())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Exercise 2:__\n",
    "\n",
    "Write a function which takes in our dataframe \"df\" and checks if the index of our dataframe entirely increments in 5 min intervals.\n",
    "The output below shows a timestamp where a time interval > 5 min occurs together with the actual time period present at that time stamp:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your fucntions finds any interval not equal to 5 min, it should return the position where this occurs (e.g. row 783) and duration of the interval at that position (e.g. row 783: 25 min). The following lines show you more useful operations to write this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the purpose of demonstration, I here import a time series with a DateTimeIndex\n",
    "df_dtindex = pd.read_pickle('../data/marginal_emissions_dtindex.pkl')\n",
    "df_dtindex.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dtindex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dtindex.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see how a DateTimeIndex is made up of individual time stamp class objects\n",
    "df_dtindex.index[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_dtindex.index[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see what happens if you perform mathematical operations in two Timestamp objects; the respective output is a Timedelta \n",
    "time_difference = df_dtindex.index[4] - df_dtindex.index[3]\n",
    "time_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(time_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the .total_seconds() method returns us any Timedelta object in seconds\n",
    "time_difference.total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Your solution 2:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit -n3 -r10\n",
    "lst = gap_finder(df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit -n1 -r3\n",
    "lst, _ = correct_timedelta(df, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Exercise 3:__\n",
    "\n",
    "If you find any such different intervals, modify our dataframe index so that it entirely increments in 5 min intervals. Use the following lines as a guide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's create an arbitrary dataframe\n",
    "df_example = pd.DataFrame(data=[[1, 2], [3, 4], [5, 6], [9, 10]], \n",
    "                          index=[dt.datetime(2018,6,1,0,0,0),\n",
    "                                dt.datetime(2018,6,1,0,0,5),\n",
    "                                dt.datetime(2018,6,1,0,0,10),\n",
    "                                dt.datetime(2018,6,1,0,0,20)], \n",
    "                          columns=['A', 'B'])\n",
    "df_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's use the pandas.date_range method to create a new index\n",
    "new_index = pd.date_range(start=dt.datetime(2018,6,1,0,0,0), end=dt.datetime(2018,6,1,0,0,20), periods=5)\n",
    "type(new_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's EXTEND the original index with our newly created DateTimeIndex; why do the NaN values occur?\n",
    "df_example = df_example.reindex(new_index)\n",
    "df_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Your Solution 3:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hypothetical number of 5min intervals given the max and min values of the df time range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.reindex(new_time_range)\n",
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = '../data/marginal_emissions_dtindex_nans.pkl'\n",
    "#pd.to_pickle(df_new, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Checking for NaNs__\n",
    "\n",
    "It is frequently the case, that machine learning models do not accept NaN values. It is therefore crucial to check your dataset for those and to clean it from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look at our dataset from BEFORE reindexing\n",
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look at our dataset from AFTER reindexing\n",
    "df_new.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Useful visualisation of NaNs__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dark shades indicate the presence of values\n",
    "#white bars indicate the presence of NaNs\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "fig = sns.heatmap(df_new.isna(), yticklabels=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Data imputation of time series__\n",
    "\n",
    "Due to the nature of time series data, the imputation of missing values needs extra attention. The potential presence of time series trends and seasonality renders imputations using e.g. mean or median deduced from the entire dataset little useful. Instead, any imputation should rather consider the local value range around a NaN value. In the following, we will see one approach of how that works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/time_series_imputation.jpg\"> <br/>\n",
    "source: https://www.hindawi.com/journals/mpe/2010/513810/fig9/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use the .rolling method to calculate the rolling mean composed of always 30 subsequent values\n",
    "#the .assign method adds a new column with our rolling mean to df_new, all of which we save in df_impute\n",
    "\n",
    "df_impute = df_new.assign(rolling_mean=df_new['t CO2-e / MWh'].rolling(window=30, min_periods=1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_impute.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_impute.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we use the numpy.where() method to replace only NaNs with values from the rolling_mean column\n",
    "df_impute['t CO2-e / MWh'] = np.where(df_impute['t CO2-e / MWh'].isnull(),\\\n",
    "                                  df_impute['rolling_mean'], df_impute['t CO2-e / MWh'])\n",
    "\n",
    "df_impute.drop(columns='rolling_mean', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's see if everything worked\n",
    "df_impute.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "df_impute[df_impute['t CO2-e / MWh'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_impute.to_pickle('../data/train_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsr_teaching",
   "language": "python",
   "name": "dsr_teaching"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
