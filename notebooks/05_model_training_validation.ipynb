{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Training an XGBoost model__\n",
    "\n",
    "XGBoost does not belong to classical time series models, however it is used frequently in the data science community for time series forecasts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Data preparation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/train_time_features.pkl'\n",
    "df = pd.read_pickle(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our lagging operation caused the introduction of NaN values into our dataset which need to be removed before the xgboost\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __train / validation split__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_ts(df, relative_train, maximal_lag, horizon):\n",
    "    '''\n",
    "    Time series (ts) split function creates a train/test set under consideration of potential overlap between the two due to lag processing\n",
    "    X_train, y_train, X_test, y_test = ...\n",
    "    df=must contain target column as \"target\"; all other columns must be used as features\n",
    "    percentage_train=how much of the total dataset shall be used for training; must be added between 0 - 1\n",
    "    maximal_lag=out of all lag feature engineering, enter the maximal lag number\n",
    "    '''\n",
    "    k = int(df.shape[0] * relative_train)\n",
    "    data_train = df.iloc[:k,:]\n",
    "    #to avoid overlapping of train and test data, a gap of the maximal lag - 1 must be included between the two sets\n",
    "    data_test = df.iloc[k+maximal_lag:,:]\n",
    "    \n",
    "    assert data_train.index.max() < data_test.index.min()\n",
    "    \n",
    "    #returns in the sequence X_train, y_train, X_test, y_test\n",
    "    return (data_train.drop(columns=[f'horizon{horizon}','t CO2-e / MWh'], axis=1), data_train[f'horizon{horizon}'],\n",
    "            data_test.drop(columns=[f'horizon{horizon}','t CO2-e / MWh'], axis=1), data_test[f'horizon{horizon}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Model training__\n",
    "\n",
    "Initially, we will do the model training without the lag features together. In an exerice, you will do it yourself with the entire feature set, i.e. including the lag features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(columns=['lag1', 'lag2', 'lag3', 'lag4', 'lag5', 'lag6', 'lag7', 'lag8', 'lag9', 'lag10', 'lag11', 'lag12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_validation, y_validation = train_test_ts(\n",
    "    df=df1,\n",
    "    relative_train=0.8,\n",
    "    maximal_lag=12,\n",
    "    horizon=0)\n",
    "\n",
    "print(df1.columns)\n",
    "\n",
    "print(X_train.index.max())\n",
    "print(X_validation.index.min())\n",
    "\n",
    "assert X_train.index.max() < X_validation.index.min()\n",
    "\n",
    "model = xgb.XGBRegressor(max_depth=5,\n",
    "                         learning_rate=0.1,\n",
    "                         num_estimators=100,\n",
    "                         n_jobs=3,\n",
    "                         reg_alpha=0.05,\n",
    "                         reg_lambda=0,\n",
    "                        )\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "#joblib.dump(model, '../model_all_features.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Now we have successfully trained the model. However, we have not evaluated the model yet. Let's do that with our last notebook in mind.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Exercise 1:__\n",
    "\n",
    "Write a function which takes our train data (X_train, y_train), our validation data (X_test, y_test), and our trained model as input and which returns the MAE, MAPE, and SMAPE of the train and test data. Use your function to asses the errors of the train and of the validation set. What is it that the MAPE is showing and why? How do you interpret the outcomes of the train and validation errors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Your solution 1:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors(model, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    #your code here\n",
    "    \n",
    "    print(f'train_MAE: {train_mae}')\n",
    "    print(f'test_MAE: {test_mae}')\n",
    "    print(f'train_SMAPE: {train_SMAPE}')\n",
    "    print(f'test_SMAPE: {test_SMAPE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors(model, X_train, y_train, X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Exercise 2:__\n",
    "\n",
    "Illustrate a comparison of the validation set (y_validation) and the forecasted values. Illustrate a period of i) 48 h and of ii) 4 h."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Your solution 2:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Exercise 3:__\n",
    "\n",
    "Perform the xgboost training again using the entire dataframe including the lag features. Save the resulting model. Check the error metrics and visualise the results as above. What do you see? How do you interpret it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Your solution 3:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Exercise 4:__\n",
    "\n",
    "Take our test set and perform all data processing (cleaning, feature engineering) as we did with our training set. Use the saved model to make predicitons on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Your solution 4:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Feature importances__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def plot_feature_importances(rf, cols, model_dir):\n",
    "    importances = pd.DataFrame()\n",
    "    importances.loc[:, 'importances'] = rf.feature_importances_\n",
    "    importances.loc[:, 'features'] = cols\n",
    "    importances.sort_values('importances', inplace=True)\n",
    "    f, a = plt.subplots()\n",
    "    importances.plot(ax=a, kind='bar', x='features', y='importances')\n",
    "    plt.gcf().subplots_adjust(bottom=0.3)\n",
    "    f.savefig(os.path.join(model_dir, 'importances.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.style.use('ggplot')\n",
    "#plot_feature_importances(model, X_train.columns.to_list(), '../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
