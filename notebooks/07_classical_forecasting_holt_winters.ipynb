{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Classical forecasting methods__\n",
    "\n",
    "Classical time series modelling is a well developed field, that offers models that are the best option for many problems.\n",
    "\n",
    "Commonly these models rely on decomposition of the time series into it's components, and have stricter requirements (such as stationarity or no seasonality) than more general machine learning approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Forecasting with the Holt-Winters method__\n",
    "\n",
    "The Holt-Winters method takes the trend as well as seasonality of a time series into account. Note that it only considers time features (hour of day, month of year etc) and no exogenous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "display(HTML(\"<table><tr><td><img src='../images/Holt_Winter_additive.png' width='400'></td><td><img src='../images/Holt_Winter_multiplicative.png'width='280'></td></tr></table>\"))\n",
    "display(HTML(\"<i>l<sub>t</sub></i>: level\"))\n",
    "display(HTML(\"<i>b<sub>t</sub></i>: trend\"))\n",
    "display(HTML(\"<i>s<sub>t</sub></i>: seasonal component\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Hyndman and Athanasopoulos, Forecasting: Principles and Practice](https://otexts.com/fpp2/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings #ignore harmless warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set desired DateTimeIndex as index and parse dates leads to DateTimeIndex right away\n",
    "df = pd.read_csv('../data/airline_passengers.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "#resample DateTimeIndex as to beginning of each month\n",
    "df.index.freq = 'MS'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.index.min())\n",
    "print(df.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the .describe method provides a good overview over the most basic statistics of the feature columns of a dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "#we use the dataset 'Thousands of Passengers' as it is a convenient dataset for demonstration purposes\n",
    "fig = sns.lineplot(x=df.index, y=df['Thousands of Passengers'], color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Train / test split__\n",
    "\n",
    "Apart from providing data, there is no room to tweak time series forecasts with any feature engineering. Hence, the risk of overfitting to the existing dataset is little, which is ẃhy we do not split the dataset into train / validation / test here, but only into train and test data.\n",
    "\n",
    "Rule of thumb: set the length of your test set equal to your intended forecast size. Here: 3 seasons or 36 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as usually, let us split up the dataset into a train / validation / test set\n",
    "train_data = df.iloc[:108]\n",
    "test_data = df.iloc[108:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Fitting model to Holt-Winters model__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Additive model__\n",
    "\n",
    "An additive model is linear where changes over time are consistently made by the same amount. <br/>\n",
    "A linear trend is a straight line.<br/>\n",
    "A linear seasonality has the same frequency (width of cycles) and amplitude (height of cycles)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Multiplicative model__\n",
    "\n",
    "A multiplicative model is nonlinear, such as quadratic or exponential. Changes increase or decrease over time.<br/>\n",
    "A nonlinear trend is a curved line.<br/>\n",
    "A non-linear seasonality has an increasing or decreasing frequency and/or amplitude over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "fitted_model = ExponentialSmoothing(train_data['Thousands of Passengers'],\n",
    "                                    trend='mul',seasonal='mul',\n",
    "                                    seasonal_periods=12).fit()\n",
    "\n",
    "#the trend is multiplicative as it shows exponential growth\n",
    "#the seasonality is multiplicative as it shows an increasing amplitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Validation of fitted model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forecast of 36 periods (hence 36 months) into future\n",
    "test_predictions = fitted_model.forecast(36).rename('HW Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Thousands of Passengers'].plot(legend=True,label='train')\n",
    "test_data['Thousands of Passengers'].plot(legend=True,label='validation',figsize=(10,7));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Thousands of Passengers'].plot(legend=True,label='train')\n",
    "test_data['Thousands of Passengers'].plot(legend=True,label='validation',figsize=(10,7))\n",
    "test_predictions.plot(legend=True,label='prediction');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Model evaluation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have already seen the MAE\n",
    "MAE = mean_absolute_error(test_data, test_predictions)\n",
    "MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_MAE = MAE/df.mean()\n",
    "relative_MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Root mean square error (RMSE)__\n",
    "\n",
    "The RMSE is a good metric in order to specifically penalise large deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$RMSE = \\sqrt{\\frac{\\sum\\limits_{t=1}^n(F_t - A_t)^2}{n}}$ <br/>\n",
    "<br/>\n",
    "$F_t$: forecast value <br/>\n",
    "$A_t$: actual value <br/>\n",
    "$n$: sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(test_data, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __MAPE__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum(abs((test_data['Thousands of Passengers'] - test_predictions)\\\n",
    "                /test_data['Thousands of Passengers'])))*(100/len(test_data['Thousands of Passengers']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Stationarity__\n",
    "\n",
    "Stationary data do not feature any trend nor seasonality. Any fluctuations are noise. They are a requirement for some of the classicl methods we will get to know - it is not required for the Holt-Winter method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this dataset contains values with typical characteristics which can occur in a time series.\n",
    "df2 = pd.read_csv('../data/samples.csv',index_col=0,parse_dates=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "df2['a'].plot(ylim=[0,100],title=\"stationary data\", color='blue').autoscale(axis='x',tight=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "df2['b'].plot(ylim=[0,100],title='non-stationary data', color='blue').autoscale(axis='x',tight=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Differencing__\n",
    "Stationarity of non-stationary data can be accomplished through differencing. Differencing calculates the difference between consecutive points.\n",
    "\n",
    "$y_{t}´ = y_t - y_{t-1}$ <br/>\n",
    "<br/>\n",
    "$y_{t}´´ = (y_t - y_{t-1}) - (y_{t-1} - y_{t-2})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Using statsmodels__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.tools import diff\n",
    "\n",
    "#here, we difference our non-stationary dataset\n",
    "df2['d1'] = diff(df2['b'],k_diff=1) #use this differencing method for > 1st order differencing\n",
    "\n",
    "df2['d1'].plot(title=\"first difference data\", color='blue').autoscale(axis='x',tight=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Using pandas__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see how differencing decreases your sample size\n",
    "df2['b1'] = df2['b'] - df2['b'].shift(1) #this command subtracts the past from the present value\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['z'] = diff(df2['b'],k_diff=2)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['z1'] = df2['b'] - df2['b'].shift(2)\n",
    "df2.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsr_teaching",
   "language": "python",
   "name": "dsr_teaching"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
