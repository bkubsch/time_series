{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Time series forecasting__\n",
    "\n",
    "## References\n",
    "\n",
    "[Hyndman and Athanasopoulos, Forecasting: Principles and Practice](https://otexts.com/fpp2/)\n",
    "\n",
    "[Stationarity in time series analysis](https://towardsdatascience.com/stationarity-in-time-series-analysis-90c94f27322)\n",
    "\n",
    "[Trend, Seasonality, Moving Average, Auto Regressive Model : My Journey to Time Series Data with Interactive Code](https://towardsdatascience.com/trend-seasonality-moving-average-auto-regressive-model-my-journey-to-time-series-data-with-edc4c0c8284b)\n",
    "\n",
    "[4 Common Machine Learning Data Transforms for Time Series Forecasting](https://machinelearningmastery.com/machine-learning-data-transforms-for-time-series-forecasting/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __What is a time series?__\n",
    "\n",
    "Time series data is observed sequentially over time, with each observation associated to a timestamp.  Most commonly these timestamps are evenly spaced.\n",
    "\n",
    "There is connection (and hopefully correlation!) between samples, and that the order matters.\n",
    "\n",
    "A good time series forecast will capture genuine patterns & relationships in data, without repeating past events that don't appear again.\n",
    "- the aim is to estimate how the sequence of observations will continue into the future\n",
    "\n",
    "A good forecast will be able to identify components of the time series that change, and will often assume them to be changing in their forecasts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Applications__\n",
    "\n",
    "Given the temporal dimension of our universe, there are numerous applications of time series forecasting. \n",
    "\n",
    "A few examples are given below:\n",
    "\n",
    "- finance - stock prices\n",
    "- weather & climate - rainfall\n",
    "- accounting - annual sales, monthly costs\n",
    "- business - customer churn\n",
    "- energy - demand, generation, price\n",
    "\n",
    "The applicability of time series forecasting depends on how predictable the time series is\n",
    "\n",
    "## __Is my time series predictable?__\n",
    "\n",
    "The predictability of future values in that time series depends on\n",
    "- how well we understand the variables that contribute\n",
    "- availability of data\n",
    "- if the forecast itself affects future values (think of a forecast of economic indicators such as GDP)\n",
    "\n",
    "A key question in time series is how predictable the time series is, and if the patterns we see are anything more than random noise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Characteristics and components of a time series__\n",
    "\n",
    "The figure below shows the quarterly Australian beer production from 1992 to the second quarter of 2010. The blue lines show forecasting for two years, the dark shaded regions an 80 %, and the light shaded regions an 95 % confidence interval.\n",
    "\n",
    "Take a look at the time series plot below.  What words would you use to describe it?\n",
    "\n",
    "<img src=\"../images/australian_beer_production.png\" width=700> <br/>\n",
    "__Australian quarterly beer production with 2 years of forecasts.__ ([Hyndman and Athanasopoulos, Forecasting: Principles and Practice](https://otexts.com/fpp2/))\n",
    "\n",
    "In time series we use the following to characterize a time series:\n",
    "\n",
    "- stationarity - how the statistics of a process change over time\n",
    "- trend - a non-repeating change (inflation, population growth)\n",
    "- seasonality - a repeating change (weather seasons)\n",
    "- noise - non systematic, unpredictable\n",
    "\n",
    "Question to class - is a time series with a trend stationary or non-stationary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Exogeneous variables__\n",
    "\n",
    "Imagine we are forecasting sales at a store\n",
    "- it is likely that knowing the sales on the previous day is useful\n",
    "- it is also likely that knowing other variables such as which store and weather are useful\n",
    "\n",
    "The last point is an example of using exogenous predictors.  \n",
    "\n",
    "## __Specifying models__\n",
    "\n",
    "For the example of hourly electricity demand $ED$, an exogeneous model would look like the following:\n",
    "\n",
    "$ED = f(current\\ temperature, strength\\ of\\ economy, population, time\\ of\\ day, day\\ of\\ week, error)$\n",
    "\n",
    "A model using only previous values of the target looks like:\n",
    "\n",
    "$ED_{t+1} = f(ED_t, ED_{t-1}, ED_{t-2}, ED_{t-3}, ... ,error)$\n",
    "\n",
    "It is also possible to combine these into a mixed model:\n",
    "\n",
    "$ED_{t+1} = f(ED_t, current\\ temperature, time\\ of\\ day, day\\ of\\ week, error)$\n",
    "\n",
    "## __What data do I have at test time?__\n",
    "\n",
    "When using any features (exogeneous or not) it is crucial that this data is always available when you make the prediction!\n",
    "\n",
    "For example, you may not be able to use the previous days sales if the data is only available a week later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Some simple forecasting methods__\n",
    "\n",
    "The simplest approaches to time series are especially important to understand as a **simple approach which should always be used as a baseline**.\n",
    "\n",
    "Quite often a simple approach will outperform a more complex approach.\n",
    "\n",
    "Here, we will look at some of the simplest forecasting methods:\n",
    "- __Drift:__ draw a line between the first and the last value and extrapolate.\n",
    "- __Mean:__ uses an unconditional sample mean as a forecast.\n",
    "- __Naive:__ takes the target value of the last timestamp.\n",
    "- __Seasonal naive:__ takes the target value of the same time point of the __LAST__ season and uses it as a forecast value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "display(HTML(\"<table><tr><td><img src='../images/drift.png' width='600'></td><td><img src='../images/seasonal_naive.png'width='600'></td></tr></table>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Hyndman and Athanasopoulos, Forecasting: Principles and Practice](https://otexts.com/fpp2/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Basic time series functionality methods in Python__\n",
    "\n",
    "Below we will look at the objects commonly used in Python for dealing with dates & times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Dates and Times__\n",
    "\n",
    "### ISO 8601\n",
    "\n",
    "An international standard for datetimes - [Wikipedia](https://en.wikipedia.org/wiki/ISO_8601).  \n",
    "\n",
    "A noteable feature of the standard is the use of `T` to separate the date & time\n",
    "\n",
    "The below are all the same time, in UTC (Z = Zulu time = UTC = GMT).\n",
    "\n",
    "```\n",
    "2019-11-28T09:18:53+00:00\n",
    "\n",
    "2019-11-28T09:18:53Z\n",
    "\n",
    "20191128T091853Z\n",
    "```\n",
    "\n",
    "We can also represent the same moment in time in another time zone (say Central European Time, which is one hour ahead of UTC):\n",
    "\n",
    "```\n",
    "2019-11-28T10:18:53+01:00\n",
    "```\n",
    "\n",
    "*Standard times* are not affected by daylight savings - be thankful if your data is stamped in or you can work in a standard time.  \n",
    "\n",
    "Working in local times is the worst case scenario for a programmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Timestamps__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a date range\n",
    "rng = pd.date_range('2016 Jul 1', periods = 10, freq = 'D')\n",
    "rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp('2016-07-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can add more details\n",
    "pd.Timestamp('2016-07-10 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and more\n",
    "pd.Timestamp('2016-07-10 10:15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of timestamp object variable\n",
    "t = pd.Timestamp('2016-07-10 10:15')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Time spans__\n",
    "\n",
    "A period of time, with an associated frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Period('2016-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Period('2016-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Period('2016-01-01 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Period('2016-01-01 10:10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.Period('2016-01-01 10:10:10', freq='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Time offsets__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timedelta('1 day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Period('2016-01-01 10:10') + pd.Timedelta('1 day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp('2016-01-01 10:10') + pd.Timedelta('1 day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp('2016-01-01 10:10') + pd.Timedelta('15 ns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Frequency settings__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html under 'DateOffset'\n",
    "# only business days:\n",
    "pd.period_range('2016-01-01 10:10', freq = 'B', periods = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible to combine frequencies. What if you want to advance by 25 hours each day. What are the 2 ways to do it?\n",
    "p1 = pd.period_range('2016-01-01 10:10', freq = '25H', periods = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = pd.period_range('2016-01-01 10:10', freq = '1D1H', periods = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamped data can be convereted to period indices with to_period and vice versa with to_timestamp\n",
    "ts = pd.Series(range(10), pd.date_range('07-10-16 8:00', periods = 10, freq = 'H'))\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_period = ts.to_period()\n",
    "ts_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_period.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_period['2016-07-10 08:30':'2016-07-10 11:45'] # we have the concept of overlap with time periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts['2016-07-10 08:30':'2016-07-10 11:45'] # we have the concept of include with timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Time zone handling__\n",
    "\n",
    "A frustrating challenge for all programmers:\n",
    "\n",
    "![](../images/tz.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = pd.date_range('3/6/2012 00:00', periods=15, freq='D')\n",
    "rng.tz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_tz = pd.date_range('3/6/2012 00:00', periods=15, freq='D', tz='Europe/London')\n",
    "rng_tz.tz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytz import common_timezones, all_timezones\n",
    "print(len(common_timezones))\n",
    "print(len(all_timezones))\n",
    "print(set(all_timezones) - set(common_timezones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#localisation of naive timestamp\n",
    "t_naive = pd.Timestamp('2016-07-10 08:50')\n",
    "t_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t_naive.tz_localize(tz = 'US/Central')\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.tz_convert('Asia/Tokyo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling of daylight saving\n",
    "rng = pd.date_range('2016-03-10', periods=10, tz='US/Central')\n",
    "ts = pd.Series(range(10), index=rng)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = pd.date_range('2016-03-10', periods=10, tz='utc')\n",
    "ts = pd.Series(range(10), index=rng)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.tz_convert('US/Central')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what happens if one hour does not exist due to daytime saving time?\n",
    "pd.Timestamp('2016-03-13 02:00:00', tz = 'US/Central')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = pd.date_range(start='2016-03-13 01', periods=3, freq='H', tz='US/Central')\n",
    "sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if we enter the winter period wp?\n",
    "wp = pd.date_range(start='2019-10-27 01', periods=5, freq='H', tz='CET')\n",
    "wp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Datetimes in DataFrames__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parsing datetime columns\n",
    "df = pd.DataFrame({'year': [2015, 2016],'month': [2, 3],'day': [4, 5],'hour': [2, 3]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(df[['year', 'month', 'day']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#truncate convenience function\n",
    "ts = pd.Series(range(10), index=pd.date_range('7/31/2015', freq='M', periods=10))\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.truncate(before='2015-10-31', after='2015-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#truncate by indexing\n",
    "ts[[0, 2, 6]].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.ix[0:10:2].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Resampling__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = pd.date_range('1/1/2011', periods=72, freq='H')\n",
    "ts = pd.Series(np.random.randn(len(rng)), index=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted = ts.asfreq('45Min', method='pad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted1 = ts.asfreq('45Min', method='backfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted = ts.asfreq('90Min', method = 'bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.resample('D').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Moving window functions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pylab\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(600, 3), index = pd.date_range('7/1/2016', freq = 'S', periods = 600), columns = ['A', 'B', 'C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.rolling_mean(df, window = 2)[1:10] # in future versions you want to resample separately\n",
    "r = df.rolling(window = 10)\n",
    "# r.agg, r.apply, r.count, r.exclusions, r.max, r.median, r.name, r.quantile, r.kurt, r.cov, r.corr, r.aggregate, r.std, r.skew, r.sum, r.var\n",
    "df.plot(style = 'k--')\n",
    "r.mean().plot(style = 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting rolling averages per columns\n",
    "df = pd.DataFrame(np.random.randn(1000, 4), index = pd.date_range('6/6/16', periods = 1000), columns = ['A', 'B', 'C', 'D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.cumsum()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rolling(window = 50).sum().plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply a custom fucntion to your data using the .apply() method\n",
    "df.rolling(window = 10).apply(lambda x: np.fabs(x - x.mean()).mean()) # x refers to any element within the defined window of 10 -> mean deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yields the value of the statistic with all the data available up to that point in time\n",
    "df.expanding(min_periods = 1).mean()[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Data transformations__\n",
    "\n",
    "Commonly in data science we apply transformations to data (i.e. standardization or normalization).  All of these transformations require an inverse.\n",
    "\n",
    "In time series transformations are often performed to remove components such as trend or seasonality\n",
    "\n",
    "Below we look at two common time series transformations.\n",
    "\n",
    "#### __Log transformation__\n",
    "\n",
    "A subset of the more general power transformations (square root, cube root, log, etc).  The power transforms attempt to make data more Gaussian.  In time series the effect can often be removing a change in variance over time.\n",
    "\n",
    "The log transform is common in finance, as it transforms exponential accumulation of returns to linear\n",
    "\n",
    "A log transform will make a process more stationary, by transforming multiplicative trends into linear trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the airline passengers dataset is a famous one to demonstrate time series forecasts\n",
    "#we will see it at other occasions throughout this course\n",
    "airline_passengers = pd.read_csv('../data/airline_passengers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "airline_passengers.plot(color='blue');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the trend of this dataset is an exponential increase\n",
    "- the periodic amplitude also increases over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_passengers_log = airline_passengers['Thousands of Passengers'].apply(lambda x: np.log10(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "airline_passengers_log.plot(color='blue');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the log transform\n",
    "- the trend became almost linear\n",
    "- the periodic amplitude remains constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Difference transform__\n",
    "\n",
    "Also known as differencing.  There are various types of differencing:\n",
    "- first order - subtracting by the previous value (t-1).  This will remove trend\n",
    "- seasonal differencing - subtracting by the previous value the season before, such as yesterday, last week or last year\n",
    "\n",
    "First order differencing can be repeated to remove second order trends.\n",
    "\n",
    "Below we apply a first order difference to our passengers dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = airline_passengers.loc[:, 'Thousands of Passengers'].diff(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff.plot(color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The differencing transform has removed our linear growth trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Exercise__\n",
    "\n",
    "- load the `co2_mm_mlo.csv` dataset\n",
    "- create a time stamp column\n",
    "- is the time series stationary?\n",
    "- does the time series have a trend?\n",
    "- does the time series implement seasonality?\n",
    "\n",
    "Based on your visual examination, apply either / or the transforms we discussed above (log / differencing)\n",
    "\n",
    "Finally, implement a naive & seasonal naive forecast for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __#1__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/co2_mm_mlo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, 'average'].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __#2__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n3 -r10 #number of measurents: n*r\n",
    "lst = []\n",
    "\n",
    "for i in data.decimal_date:\n",
    "    time = i\n",
    "    year = dt.date(int(time), 1, 1)\n",
    "    day = pd.Timedelta(days=(time % 1 * 365))\n",
    "    datetime = str(year + day)\n",
    "    lst.append(datetime)\n",
    "    \n",
    "data['datetime'] = pd.to_datetime(lst)\n",
    "data.set_index('datetime', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['year', 'month', 'decimal_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What about speed?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n3 -r10 #number of measurents: n*r\n",
    "df_new = data.decimal_date.astype(str).str.split('.', expand=True)\n",
    "df_new['year'] = pd.to_datetime(df_new[0])\n",
    "df_new['day'] = pd.to_timedelta(('0.' + df_new[1]).astype(float)*365, unit='d')\n",
    "df_new['Timestamp'] = df_new['year'] + df_new['day']\n",
    "df_new.Timestamp = df_new.Timestamp.dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.set_index(df_new['Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, 'average'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __#3__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, as visual inspection suggests the existence of a trend and seasonality. Hence, unconditional mean != const. and variance != const, arguing against a stationary dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __#4__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __#5__\n",
    "\n",
    "Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __#6__\n",
    "\n",
    "find the respective commands above in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __#7a__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here, we set the desired time range for our naive forecast\n",
    "index = pd.date_range(start=data.index.max() + pd.Timedelta(days=1), freq='M', periods=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's create our naive values\n",
    "values = []\n",
    "for i in index:\n",
    "    x = data.average[-1]\n",
    "    values.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we append our new index and naive forecast list to the existing dataframe; note that whichever columns we do not fill explicitly, they will be filled with nan values\n",
    "df_append = pd.DataFrame(data={'average':values}, index=index)\n",
    "data_naive = data.append(df_append, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the sake of visualisation, we plot only the lastt 200 data points\n",
    "data_naive.iloc[-200:,:].loc[:, 'average'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __#7b__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's do the seasonal naice forecast for a period of two years\n",
    "#this is the only way I found to circumvent leapyear issues as Timedelta appears limited beyond timescales of one year\n",
    "\n",
    "index = []\n",
    "for i in data.index[-24:]:\n",
    "    i = i.replace(i.year + 2)\n",
    "    index.append(i)\n",
    "    \n",
    "index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "for i in data.iloc[-24:, :].average:\n",
    "    x = i\n",
    "    values.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_append = pd.DataFrame({'average':values}, index=index)\n",
    "df_seasonal_naive = data.append(df_append, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seasonal_naive.iloc[-100:-24].loc[:, 'average'].plot(color='blue')\n",
    "df_seasonal_naive.iloc[-24:].loc[:, 'average'].plot(color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Can you guess why the seasonal forecast features this abrupt shift? Note that besides seasonality our dataset bears a trend as well.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsr_teaching",
   "language": "python",
   "name": "dsr_teaching"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
