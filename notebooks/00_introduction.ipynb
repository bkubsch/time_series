{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Time series forecasting__\n",
    "\n",
    "## References\n",
    "\n",
    "[Hyndman and Athanasopoulos, Forecasting: Principles and Practice](https://otexts.com/fpp2/)\n",
    "\n",
    "[Stationarity in time series analysis](https://towardsdatascience.com/stationarity-in-time-series-analysis-90c94f27322)\n",
    "\n",
    "[Trend, Seasonality, Moving Average, Auto Regressive Model : My Journey to Time Series Data with Interactive Code](https://towardsdatascience.com/trend-seasonality-moving-average-auto-regressive-model-my-journey-to-time-series-data-with-edc4c0c8284b)\n",
    "\n",
    "[4 Common Machine Learning Data Transforms for Time Series Forecasting](https://machinelearningmastery.com/machine-learning-data-transforms-for-time-series-forecasting/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __What is a time series?__\n",
    "\n",
    "Time series data is observed sequentially over time, with each observation associated to a timestamp.  Most commonly these timestamps are evenly spaced.\n",
    "\n",
    "There is connection (and hopefully correlation!) between samples, and that the order matters.\n",
    "\n",
    "A good time series forecast will capture genuine patterns & relationships in data, without repeating past events that don't appear again.\n",
    "- the aim is to estimate how the sequence of observations will continue into the future\n",
    "\n",
    "A good forecast will be able to identify components of the time series that change, and will often assume them to be changing in their forecasts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Applications__\n",
    "\n",
    "Given the temporal dimension of our universe, there are numerous applications of time series forecasting. \n",
    "\n",
    "A few examples are given below:\n",
    "\n",
    "- finance - stock prices\n",
    "- weather & climate - rainfall\n",
    "- accounting - annual sales, monthly costs\n",
    "- business - customer churn\n",
    "- energy - demand, generation, price\n",
    "\n",
    "The applicability of time series forecasting depends on how predictable the time series is\n",
    "\n",
    "## __Is my time series predictable?__\n",
    "\n",
    "The predictability of future values in that time series depends on\n",
    "- how well we understand the variables that contribute\n",
    "- availability of data\n",
    "- if the forecast itself affects future values (think of a forecast of economic indicators such as GDP)\n",
    "\n",
    "A key question in time series is how predictable the time series is, and if the patterns we see are anything more than random noise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characteristics and components of a time series\n",
    "\n",
    "The figure below shows the quarterly Australian beer production from 1992 to the second quarter of 2010. The blue lines show forecasting for two years, the dark shaded regions an 80 %, and the light shaded regions an 95 % confidence interval.\n",
    "\n",
    "Take a look at the time series plot below.  What words would you use to describe it?\n",
    "\n",
    "<img src=\"../images/australian_beer_production.png\" width=700> <br/>\n",
    "__Australian quarterly beer production with 2 years of forecasts.__ ([Hyndman and Athanasopoulos, Forecasting: Principles and Practice](https://otexts.com/fpp2/))\n",
    "\n",
    "In time series we use the following to characterize a time series:\n",
    "\n",
    "- stationarity - how the statistics of a process change over time\n",
    "- trend - a non-repeating change (inflation, population growth)\n",
    "- seasonality - a repeating change (weather seasons)\n",
    "- noise - non systematic, unpredictable\n",
    "\n",
    "Question to class - is a time series with a trend stationary or non-stationary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exogeneous variables\n",
    "\n",
    "Imagine we are forecasting sales at a store\n",
    "- it is likely that knowing the sales on the previous day is useful\n",
    "- it is also likely that knowing other variables such as which store and weather are useful\n",
    "\n",
    "The last point is an example of using exogenous predictors.  \n",
    "\n",
    "## Specifying models\n",
    "\n",
    "For the example of hourly electricity demand $ED$, an exogeneous model would look like the following:\n",
    "\n",
    "$ED = f(\\text{current temperature}, strength\\ of\\ economy, population, time\\ of\\ day, day\\ of\\ week, error)$\n",
    "\n",
    "A model using only previous values of the target looks like:\n",
    "\n",
    "$ED_{t+1} = f(ED_t, ED_{t-1}, ED_{t-2}, ED_{t-3}, ... ,error)$\n",
    "\n",
    "It is also possible to combine these into a mixed model:\n",
    "\n",
    "$ED_{t+1} = f(ED_t, current\\ temperature, time\\ of\\ day, day\\ of\\ week, error)$\n",
    "\n",
    "## What data do I have at test time?\n",
    "\n",
    "When using any features (exogeneous or not) it is crucial that this data is always available when you make the prediction!\n",
    "\n",
    "For example, you may not be able to use the previous days sales if the data is only available a week later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Some simple forecasting methods__\n",
    "\n",
    "The simplest approaches to time series are especially important to understand as a **simple approach should always be used as a baseline**.\n",
    "\n",
    "Quite often a simple approach will outperform a more complex approach.\n",
    "\n",
    "Here, we will look at some of the simplest forecasting methods:\n",
    "- __Drift:__ draw a line between the first and the last value and extrapolate.\n",
    "- __Mean:__ uses an unconditional, sample mean as a forecast.\n",
    "- __Naive:__ takes the target value of the last timestamp.\n",
    "- __Seasonal naive:__ takes the target value of the same time point of the __LAST__ season and uses it as a forecast value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td><img src='../images/drift.png' width='600'></td><td><img src='../images/seasonal_naive.png'width='600'></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "display(HTML(\"<table><tr><td><img src='../images/drift.png' width='600'></td><td><img src='../images/seasonal_naive.png'width='600'></td></tr></table>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Hyndman and Athanasopoulos, Forecasting: Principles and Practice](https://otexts.com/fpp2/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Basic time series functionality methods in Python__\n",
    "\n",
    "Below we will look at the objects commonly used in Python for dealing with dates & times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Dates and Times__\n",
    "\n",
    "### ISO 8601\n",
    "\n",
    "An international standard for datetimes - [Wikipedia](https://en.wikipedia.org/wiki/ISO_8601).  \n",
    "\n",
    "A noteable feature of the standard is the use of `T` to separate the date & time\n",
    "\n",
    "The below are all the same time, in UTC (Z = Zulu time = UTC = GMT).\n",
    "\n",
    "```\n",
    "2019-11-28T09:18:53+00:00\n",
    "\n",
    "2019-11-28T09:18:53Z\n",
    "\n",
    "20191128T091853Z\n",
    "```\n",
    "\n",
    "We can also represent the same moment in time in another time zone (say Central European Time, which is one hour ahead of UTC):\n",
    "\n",
    "```\n",
    "2019-11-28T10:18:53+01:00\n",
    "```\n",
    "\n",
    "*Standard times* are not affected by daylight savings - be thankful if your data is stamped in or you can work in a standard time.  \n",
    "\n",
    "Working in local times is the worst case scenario for a programmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Timestamps__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2016-07-01', '2016-07-02', '2016-07-03', '2016-07-04', '2016-07-05', '2016-07-06', '2016-07-07', '2016-07-08', '2016-07-09', '2016-07-10'], dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a date range\n",
    "rng = pd.date_range('2016 Jul 1', periods = 10, freq = 'D')\n",
    "rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-07-10 00:00:00')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Timestamp('2016-07-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-07-10 10:00:00')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can add more details\n",
    "pd.Timestamp('2016-07-10 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-07-10 10:15:00')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and more\n",
    "pd.Timestamp('2016-07-10 10:15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of timestamp object variable\n",
    "t = pd.Timestamp('2016-07-10 10:15')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Time spans__\n",
    "\n",
    "A period of time, with an associated frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2016-01', 'M')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Period('2016-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2016-01-01', 'D')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Period('2016-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2016-01-01 10:00', 'H')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Period('2016-01-01 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2016-01-01 10:10', 'T')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Period('2016-01-01 10:10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2016-01-01 10:10:10', 'S')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Period('2016-01-01 10:10:10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Time offsets__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('1 days 00:00:00')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Timedelta('1 day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2016-01-02 10:10', 'T')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Period('2016-01-01 10:10') + pd.Timedelta('1 day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-01-02 10:10:00')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Timestamp('2016-01-01 10:10') + pd.Timedelta('1 day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-01-01 10:10:00.000000015')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Timestamp('2016-01-01 10:10') + pd.Timedelta('15 ns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Frequency settings__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeriodIndex(['2016-01-01', '2016-01-04', '2016-01-05', '2016-01-06', '2016-01-07', '2016-01-08', '2016-01-11', '2016-01-12', '2016-01-13', '2016-01-14'], dtype='period[B]', freq='B')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only business days:\n",
    "pd.period_range('2016-01-01 10:10', freq = 'B', periods = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible to combine frequencies. What if you want to advance by 25 hours each day. What are the 2 ways to do it?\n",
    "p1 = pd.period_range('2016-01-01 10:10', freq = '25H', periods = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = pd.period_range('2016-01-01 10:10', freq = '1D1H', periods = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeriodIndex(['2016-01-01 10:00', '2016-01-02 11:00', '2016-01-03 12:00', '2016-01-04 13:00', '2016-01-05 14:00', '2016-01-06 15:00', '2016-01-07 16:00', '2016-01-08 17:00', '2016-01-09 18:00', '2016-01-10 19:00'], dtype='period[25H]', freq='25H')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeriodIndex(['2016-01-01 10:00', '2016-01-02 11:00', '2016-01-03 12:00', '2016-01-04 13:00', '2016-01-05 14:00', '2016-01-06 15:00', '2016-01-07 16:00', '2016-01-08 17:00', '2016-01-09 18:00', '2016-01-10 19:00'], dtype='period[25H]', freq='25H')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016-07-10 08:00:00    0\n",
       "2016-07-10 09:00:00    1\n",
       "2016-07-10 10:00:00    2\n",
       "2016-07-10 11:00:00    3\n",
       "2016-07-10 12:00:00    4\n",
       "2016-07-10 13:00:00    5\n",
       "2016-07-10 14:00:00    6\n",
       "2016-07-10 15:00:00    7\n",
       "2016-07-10 16:00:00    8\n",
       "2016-07-10 17:00:00    9\n",
       "Freq: H, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# timestamped data can be convereted to period indices with to_period and vice versa with to_timestamp\n",
    "ts = pd.Series(range(10), pd.date_range('07-10-16 8:00', periods = 10, freq = 'H'))\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016-07-10 08:00    0\n",
       "2016-07-10 09:00    1\n",
       "2016-07-10 10:00    2\n",
       "2016-07-10 11:00    3\n",
       "2016-07-10 12:00    4\n",
       "2016-07-10 13:00    5\n",
       "2016-07-10 14:00    6\n",
       "2016-07-10 15:00    7\n",
       "2016-07-10 16:00    8\n",
       "2016-07-10 17:00    9\n",
       "Freq: H, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_period = ts.to_period()\n",
    "ts_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016-07-10 08:00    0\n",
       "2016-07-10 09:00    1\n",
       "2016-07-10 10:00    2\n",
       "2016-07-10 11:00    3\n",
       "Freq: H, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_period['2016-07-10 08:30':'2016-07-10 11:45'] # we have the concept of overlap with time periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016-07-10 09:00:00    1\n",
       "2016-07-10 10:00:00    2\n",
       "2016-07-10 11:00:00    3\n",
       "Freq: H, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts['2016-07-10 08:30':'2016-07-10 11:45'] # we have the concept of include with timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Time zone handling__\n",
    "\n",
    "A frustrating challenge for all programmers:\n",
    "\n",
    "![](../images/tz.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = pd.date_range('3/6/2012 00:00', periods=15, freq='D')\n",
    "rng.tz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DstTzInfo 'Europe/London' LMT-1 day, 23:59:00 STD>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng_tz = pd.date_range('3/6/2012 00:00', periods=15, freq='D', tz='Europe/London')\n",
    "rng_tz.tz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n",
      "592\n",
      "{'Mexico/BajaNorte', 'Africa/Asmera', 'W-SU', 'Asia/Dacca', 'US/Michigan', 'GB', 'Asia/Chungking', 'America/Virgin', 'Etc/Zulu', 'Pacific/Yap', 'Etc/GMT-6', 'America/Atka', 'UCT', 'Europe/Belfast', 'Etc/GMT+5', 'America/Mendoza', 'America/Jujuy', 'Asia/Ashkhabad', 'Antarctica/South_Pole', 'Japan', 'Etc/GMT-4', 'Pacific/Truk', 'Australia/LHI', 'Etc/GMT+6', 'Etc/GMT+12', 'Pacific/Samoa', 'America/Fort_Wayne', 'Jamaica', 'Australia/ACT', 'Etc/GMT+3', 'GMT+0', 'Australia/NSW', 'MET', 'Europe/Tiraspol', 'MST7MDT', 'Israel', 'Etc/GMT+9', 'Australia/Victoria', 'GMT-0', 'Etc/GMT-13', 'Australia/Tasmania', 'Etc/GMT-2', 'NZ', 'Hongkong', 'Etc/UCT', 'Canada/Saskatchewan', 'Egypt', 'America/Montreal', 'America/Rosario', 'Pacific/Johnston', 'Atlantic/Jan_Mayen', 'America/Porto_Acre', 'Asia/Calcutta', 'Chile/EasterIsland', 'Asia/Istanbul', 'ROK', 'Etc/GMT', 'GMT0', 'Cuba', 'Kwajalein', 'Iceland', 'Australia/South', 'Etc/GMT-7', 'Etc/GMT+11', 'WET', 'America/Ensenada', 'EST', 'EET', 'CST6CDT', 'Etc/GMT-10', 'HST', 'Asia/Katmandu', 'Asia/Ulan_Bator', 'Etc/Universal', 'America/Knox_IN', 'Chile/Continental', 'Singapore', 'Etc/GMT+1', 'Australia/Yancowinna', 'Asia/Kashgar', 'Brazil/West', 'Iran', 'Mexico/BajaSur', 'Libya', 'Etc/GMT-3', 'Asia/Chongqing', 'Etc/GMT+2', 'Asia/Harbin', 'Asia/Macao', 'GB-Eire', 'Etc/GMT-11', 'PST8PDT', 'Etc/GMT-0', 'Atlantic/Faeroe', 'America/Catamarca', 'Etc/GMT0', 'Brazil/DeNoronha', 'Navajo', 'Etc/GMT-1', 'ROC', 'CET', 'Etc/UTC', 'Etc/GMT+4', 'America/Cordoba', 'Greenwich', 'Australia/North', 'NZ-CHAT', 'Etc/Greenwich', 'Asia/Thimbu', 'Zulu', 'Asia/Tel_Aviv', 'Asia/Rangoon', 'America/Indianapolis', 'Universal', 'Etc/GMT-8', 'Etc/GMT-14', 'Eire', 'America/Shiprock', 'Australia/West', 'Etc/GMT+8', 'America/Louisville', 'US/Aleutian', 'America/Buenos_Aires', 'Etc/GMT+10', 'Brazil/Acre', 'Etc/GMT-9', 'Canada/Yukon', 'Africa/Timbuktu', 'Poland', 'US/Indiana-Starke', 'Europe/Nicosia', 'Brazil/East', 'Turkey', 'Asia/Ujung_Pandang', 'US/Samoa', 'PRC', 'Mexico/General', 'Etc/GMT-5', 'Australia/Canberra', 'Etc/GMT+0', 'Etc/GMT+7', 'US/East-Indiana', 'Etc/GMT-12', 'Portugal', 'America/Santa_Isabel', 'MST', 'America/Coral_Harbour', 'America/Argentina/ComodRivadavia', 'Asia/Saigon', 'EST5EDT', 'Australia/Queensland', 'Pacific/Ponape'}\n"
     ]
    }
   ],
   "source": [
    "from pytz import common_timezones, all_timezones\n",
    "print(len(common_timezones))\n",
    "print(len(all_timezones))\n",
    "print(set(all_timezones) - set(common_timezones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-07-10 08:50:00')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#localisation of naive timestamp\n",
    "t_naive = pd.Timestamp('2016-07-10 08:50')\n",
    "t_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-07-10 08:50:00-0500', tz='US/Central')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = t_naive.tz_localize(tz = 'US/Central')\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-07-10 22:50:00+0900', tz='Asia/Tokyo')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.tz_convert('Asia/Tokyo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016-03-10 00:00:00-06:00    0\n",
       "2016-03-11 00:00:00-06:00    1\n",
       "2016-03-12 00:00:00-06:00    2\n",
       "2016-03-13 00:00:00-06:00    3\n",
       "2016-03-14 00:00:00-05:00    4\n",
       "2016-03-15 00:00:00-05:00    5\n",
       "2016-03-16 00:00:00-05:00    6\n",
       "2016-03-17 00:00:00-05:00    7\n",
       "2016-03-18 00:00:00-05:00    8\n",
       "2016-03-19 00:00:00-05:00    9\n",
       "Freq: D, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#handling of daylight saving\n",
    "rng = pd.date_range('2016-03-10', periods=10, tz='US/Central')\n",
    "ts = pd.Series(range(10), index=rng)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016-03-10 00:00:00+00:00    0\n",
       "2016-03-11 00:00:00+00:00    1\n",
       "2016-03-12 00:00:00+00:00    2\n",
       "2016-03-13 00:00:00+00:00    3\n",
       "2016-03-14 00:00:00+00:00    4\n",
       "2016-03-15 00:00:00+00:00    5\n",
       "2016-03-16 00:00:00+00:00    6\n",
       "2016-03-17 00:00:00+00:00    7\n",
       "2016-03-18 00:00:00+00:00    8\n",
       "2016-03-19 00:00:00+00:00    9\n",
       "Freq: D, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = pd.date_range('2016-03-10', periods=10, tz='utc')\n",
    "ts = pd.Series(range(10), index=rng)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016-03-09 18:00:00-06:00    0\n",
       "2016-03-10 18:00:00-06:00    1\n",
       "2016-03-11 18:00:00-06:00    2\n",
       "2016-03-12 18:00:00-06:00    3\n",
       "2016-03-13 19:00:00-05:00    4\n",
       "2016-03-14 19:00:00-05:00    5\n",
       "2016-03-15 19:00:00-05:00    6\n",
       "2016-03-16 19:00:00-05:00    7\n",
       "2016-03-17 19:00:00-05:00    8\n",
       "2016-03-18 19:00:00-05:00    9\n",
       "Freq: D, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.tz_convert('US/Central')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NonExistentTimeError",
     "evalue": "2016-03-13 02:00:00",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNonExistentTimeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-138a79ed5670>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#what happens if one hour does not exist due to datetime saving time?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2016-03-13 02:00:00'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'US/Central'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mpandas/_libs/tslibs/timestamps.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.timestamps.Timestamp.__new__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.convert_to_tsobject\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.convert_str_to_tsobject\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/tzconversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.tzconversion.tz_localize_to_utc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNonExistentTimeError\u001b[0m: 2016-03-13 02:00:00"
     ]
    }
   ],
   "source": [
    "#what happens if one hour does not exist due to datetime saving time?\n",
    "pd.Timestamp('2016-03-13 02:00:00', tz = 'US/Central')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Datetimes in DataFrames__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parsing datetime columns\n",
    "df = pd.DataFrame({'year': [2015, 2016],'month': [2, 3],'day': [4, 5],'hour': [2, 3]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(df[['year', 'month', 'day']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#truncate convenience function\n",
    "ts = pd.Series(range(10), index=pd.date_range('7/31/2015', freq='M', periods=10))\n",
    "ts.truncate(before='2015-10-31', after='2015-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#truncate by indexing\n",
    "ts[[0, 2, 6]].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.ix[0:10:2].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Resampling__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = pd.date_range('1/1/2011', periods=72, freq='H')\n",
    "ts = pd.Series(np.random.randn(len(rng)), index=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted = ts.asfreq('45Min', method='pad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted1 = ts.asfreq('45Min', method='backfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted = ts.asfreq('90Min', method = 'bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.resample('D').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Moving window functions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pylab\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(600, 3), index = pd.date_range('7/1/2016', freq = 'S', periods = 600), columns = ['A', 'B', 'C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.rolling_mean(df, window = 2)[1:10] # in future versions you want to resample separately\n",
    "r = df.rolling(window = 10)\n",
    "# r.agg, r.apply, r.count, r.exclusions, r.max, r.median, r.name, r.quantile, r.kurt, r.cov, r.corr, r.aggregate, r.std, r.skew, r.sum, r.var\n",
    "df.plot(style = 'k--')\n",
    "r.mean().plot(style = 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting rolling averages per columns\n",
    "df = pd.DataFrame(np.random.randn(1000, 4), index = pd.date_range('6/6/16', periods = 1000), columns = ['A', 'B', 'C', 'D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.cumsum()\n",
    "df.rolling(window = 50).sum().plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply a custom fucntion to your data using the .apply() method\n",
    "df.rolling(window = 10).apply(lambda x: np.fabs(x - x.mean()).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yields the value of the statistic with all the data available up to that point in time\n",
    "df.expanding(min_periods = 1).mean()[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformations\n",
    "\n",
    "Commonly in data science we apply transformations to data (i.e. standardization or normalization).  All of these transformations require an inverse.\n",
    "\n",
    "In time series transformations are often performed to remove components such as trend or seasonality\n",
    "\n",
    "Below we look at two common time series transformations.\n",
    "\n",
    "#### __Log transformation__\n",
    "\n",
    "A subset of the more general power transformations (square root, cube root, log, etc).  The power transforms attempt to make data more Gaussian.  In time series the effect can often be removing a change in variance over time.\n",
    "\n",
    "The log transform is common in finance, as it transforms exponential accumulation of returns to linear\n",
    "\n",
    "A log transform will make a process more stationary, by transforming multiplicative trends into linear trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the airline passengers dataset is a famous one to demonstrate time series forecasts\n",
    "#we will see it at other occasions throughout this course\n",
    "airline_passengers = pd.read_csv('../data/airline_passengers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "airline_passengers.plot(color='blue');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the trend of this dataset is an exponential increase\n",
    "- the periodic amplitude also increases over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_passengers_log = airline_passengers['Thousands of Passengers'].apply(lambda x: np.log10(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "airline_passengers_log.plot(color='blue');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the log transform\n",
    "- the trend became almost linear\n",
    "- the periodic amplitude remains constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference transform\n",
    "\n",
    "Also known as differencing.  There are various types of differencing:\n",
    "- first order - subtracting by the previous value (t-1).  This will remove trend\n",
    "- seasonal differencing - subtracting by the previous value the season before, such as yesterday, last week or last year\n",
    "\n",
    "First order differencing can be repeated to remove second order trends.\n",
    "\n",
    "Below we apply a first order difference to our passengers dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = airline_passengers.loc[:, 'Thousands of Passengers'].diff(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff.plot(color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The differencing transform has removed our linear growth trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "- load the `co2_mm_mlo.csv` dataset\n",
    "- create a time stamp column\n",
    "- is the time series stationary?\n",
    "- does the time series have a trend?\n",
    "- does the time series implement seasonality?\n",
    "\n",
    "Based on your visual examination, apply either / or the transforms we discussed above (log / differencing)\n",
    "\n",
    "Finally, implement a naive & seasonal naive forecast for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/co2_mm_mlo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, 'average'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
