{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Excursion: Grid Search of time series__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "import joblib\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Kfold cross validation__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/Kfold_CV.png\"> <br/>\n",
    "source: scikit-learn.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Time series split__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/time_series_split.png\"> <br/>\n",
    "source: datascience.stackexchange.com\n",
    "<br/>\n",
    "<br/>\n",
    "__Note: the sklearn tscv does not account for leakiness__\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.01, 0.1, 0.3] #learning_rate\n",
    "max_depth = [10, 25, 50] #depth of trees\n",
    "n_estimators = [5, 10, 100] #number of base learners\n",
    "\n",
    "params = {\n",
    "    'learning_rate': learning_rate,\n",
    "    'max_depth': max_depth,\n",
    "    'n_estimators': n_estimators,\n",
    "        }\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGB_GS_ts(X_train, y_train, params, run, n_splits=2, n_jobs=7, verbose=5):\n",
    "    '''\n",
    "    Function performs GridSearch using TimeSeries CV\n",
    "    X_train, y_train\n",
    "    n_splits=number of splits in TimeSeriesCV; default:3\n",
    "    n_jobs=default: -1\n",
    "    verbose=default:5\n",
    "    '''\n",
    "    \n",
    "    model = xgb.XGBRegressor()\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    gsearch = GridSearchCV(estimator=model, cv=tscv,\n",
    "                            param_grid=params, n_jobs=n_jobs, verbose=verbose)\n",
    "\n",
    "    gsearch.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best params were: {}\".format(gsearch.best_params_))\n",
    "    \n",
    "    pd.DataFrame(gsearch.cv_results_).to_csv('{}/nem-data/trainings/grid_searches/{}_GS.csv'.format(os.environ['HOME'],run))\n",
    "    joblib.dump(gsearch, '{}/nem-data/trainings/gridsearches/{}_GS_object.pkl'.format(os.environ['HOME'], run))\n",
    "    \n",
    "    best_model = gsearch.best_estimator_\n",
    "    \n",
    "    error_test = np.sqrt(mse(y_test, best_model.predict(X_test))/y_test.mean())\n",
    "    error_train = np.sqrt(mse(y_train, best_model.predict(X_train))/y_train.mean())\n",
    "    compare_train_test_error = abs(error_test - error_train)\n",
    "    \n",
    "    settings = {\n",
    "    \"Model\": \"XGBoost\",\n",
    "    \"Feature Description\": \"sine_cosine, lag_12, horizon=0, demand, capacity, interconnectors\",\n",
    "    \"Model Description\": gsearch.best_params_\n",
    "    }\n",
    "\n",
    "    print(f\"Root mean squared percentage error: {error_train, error_test}\")\n",
    "    log_test_results(\n",
    "        settings, error_train, error_test,\n",
    "        compare_train_test_error, run\n",
    "    )\n",
    "    \n",
    "    return gsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_test_results(settings, error_train, error_test, train_test_error_difference, file_name):\n",
    "    csv_path = '{}/nem-data/trainings/grid_searches/{}_GS_log.csv'.format(os.environ['HOME'], file_name)\n",
    "    must_add_headers = False if os.path.isfile(csv_path) else True\n",
    "\n",
    "    with open(csv_path, mode='a') as test_results:\n",
    "        writer = csv.writer(test_results,\n",
    "                            delimiter=',',\n",
    "                            quotechar='\"',\n",
    "                            quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "        if must_add_headers:\n",
    "            writer.writerow([\n",
    "                'Model', 'Feature Description', \"Model Description\", \"Training error\", \"Test error\",\n",
    "                \"Difference_train_test_error\"\n",
    "            ])\n",
    "        writer.writerow([\n",
    "            settings[\"Model\"], settings[\"Feature Description\"],\n",
    "            str(settings[\"Model Description\"]), error_train, error_test,\n",
    "            train_test_error_difference\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#show log file!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsr_teaching",
   "language": "python",
   "name": "dsr_teaching"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
